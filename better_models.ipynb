{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from random import seed\n",
    "import collections\n",
    "import imblearn\n",
    "\n",
    "# Machine learning models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from imblearn.pipeline import Pipeline as imblearnPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Model evaluation and hyperparameter tuning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "\n",
    "# Constant features\n",
    "from fast_ml.utilities import display_all\n",
    "from fast_ml.feature_selection import get_constant_features\n",
    "\n",
    "# Data visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature selection methods\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(21)\n",
    "path_save = './Output/'\n",
    "df = pd.read_csv(path_save + 'finaldataset_for_ML.csv', encoding='latin-1')\n",
    "df2 = pd.read_csv(path_save + 'finaldataset_for_ML2.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Target \"0\": projetos encerrados / terminados\n",
    "Target \"1: projetos anulados\n",
    "\"\"\"\n",
    "def create_target_column(row):\n",
    "    if(row['Terminado'] == 1.0):\n",
    "        return 0\n",
    "    elif(row['Anulado'] == 1.0):\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"Existe um registo sem target\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = df.apply(lambda x: create_target_column(x), axis=1)\n",
    "df2['Target'] = df2.apply(lambda x: create_target_column(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.replace(np.nan, 0.0) #Replace nulls for 0\n",
    "clean_df.replace([np.inf, -np.inf], 0.0, inplace=True) #Replace infinites for 0\n",
    "\n",
    "clean_df2 = df2.replace(np.nan, 0.0) #Replace nulls for 0\n",
    "clean_df2.replace([np.inf, -np.inf], 0.0, inplace=True) #Replace infinites for 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     resultado_das_atividades_descontinuadas\n",
       "1                          IAE_CMVMC_ACT_BIOL\n",
       "2                                        rank\n",
       "3                        Uploads/Aplicavel_12\n",
       "4                      3_IMG_EC_RS_SERSOCIAIS\n",
       "                       ...                   \n",
       "66                     Incentivo/Cap_Proprios\n",
       "67                      Incentivo/Dispensa_Ic\n",
       "68                          Paramproj/Param_1\n",
       "69                             Resumo/Icep_75\n",
       "70                         Impactoemp/Impacto\n",
       "Name: Var, Length: 71, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_features = get_constant_features(clean_df)\n",
    "#constant_features\n",
    "\n",
    "constant_features['Var'] #Shows features that have constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existem 82 colunas constantes\n"
     ]
    }
   ],
   "source": [
    "constant_features_list = constant_features['Var'].tolist()\n",
    "constant_features_list.append('N_Proj_anon')\n",
    "constant_features_list.append('CAE_SUBCLASSE')\n",
    "constant_features_list.append('DATA_RECEPCAO')\n",
    "constant_features_list.append('NIF_anon')\n",
    "constant_features_list.append('Terminado')\n",
    "constant_features_list.append('Anulado')\n",
    "constant_features_list.append('Nproj_anon_x')\n",
    "constant_features_list.append('Nproj_anon_y')\n",
    "constant_features_list.append('ANO_EXERCICIO')\n",
    "constant_features_list.append('ANO_EXERCICIO_VALIDOS')\n",
    "constant_features_list.append('Parametros/Ano_Cand')\n",
    "print('Existem %i colunas constantes' % len(constant_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(constant_features_list, axis=1)\n",
    "clean_df2 = clean_df2.drop(constant_features_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = clean_df.select_dtypes(include='object').columns\n",
    "object_columns_list = object_columns.tolist()\n",
    "object_columns_list.remove(\"Motivo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_df.drop(columns=object_columns_list)\n",
    "clean_df2 = clean_df2.drop(columns=object_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.drop(columns=['Target', 'Motivo'])\n",
    "y = clean_df['Target']\n",
    "scaler = MinMaxScaler() #MinMaxScaler\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X.values), columns= X.columns, index=X.index)\n",
    "X3 = clean_df2.drop(columns=['Target', 'Motivo'])\n",
    "y3 = clean_df2['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=21, train_size=0.7, test_size=0.3)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, random_state=21, train_size=0.7, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experience</th>\n",
       "      <th>Count</th>\n",
       "      <th>Columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feat1</td>\n",
       "      <td>30</td>\n",
       "      <td>RES_ANTES_DEPRECIACAO_GASTOS, GASTOS_DEPRECIAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feat2</td>\n",
       "      <td>30</td>\n",
       "      <td>GASTOS_PESSOAL, OUTROS_REDIMENTOS_GANHOS, RES_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feat3</td>\n",
       "      <td>50</td>\n",
       "      <td>GASTOS_PESSOAL, RES_ANTES_DEPRECIACAO_GASTOS, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feat4</td>\n",
       "      <td>50</td>\n",
       "      <td>VENDAS_SERVICOS_PRESTADOS, GASTOS_PESSOAL, OUT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feat5</td>\n",
       "      <td>50</td>\n",
       "      <td>GASTOS_DEPRECIACAO_AMORTIZA, Incentivo/Tx_Limi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feat6</td>\n",
       "      <td>50</td>\n",
       "      <td>RES_ANTES_DEPRECIACAO_GASTOS, GASTOS_DEPRECIAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>feat7</td>\n",
       "      <td>50</td>\n",
       "      <td>Txtfinanc/Fonte, Promotor/Nat_Jur, 3_IMG_EC_PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>allFeat</td>\n",
       "      <td>267</td>\n",
       "      <td>VENDAS_SERVICOS_PRESTADOS, SUBSIDIOS_EXPLORACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>manualFeat</td>\n",
       "      <td>22</td>\n",
       "      <td>EBITDA, EBIT, Total_Assets, Total_Liabilities,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Experience  Count                                            Columns\n",
       "0       feat1     30  RES_ANTES_DEPRECIACAO_GASTOS, GASTOS_DEPRECIAC...\n",
       "1       feat2     30  GASTOS_PESSOAL, OUTROS_REDIMENTOS_GANHOS, RES_...\n",
       "2       feat3     50  GASTOS_PESSOAL, RES_ANTES_DEPRECIACAO_GASTOS, ...\n",
       "3       feat4     50  VENDAS_SERVICOS_PRESTADOS, GASTOS_PESSOAL, OUT...\n",
       "4       feat5     50  GASTOS_DEPRECIACAO_AMORTIZA, Incentivo/Tx_Limi...\n",
       "5       feat6     50  RES_ANTES_DEPRECIACAO_GASTOS, GASTOS_DEPRECIAC...\n",
       "6       feat7     50  Txtfinanc/Fonte, Promotor/Nat_Jur, 3_IMG_EC_PR...\n",
       "7     allFeat    267  VENDAS_SERVICOS_PRESTADOS, SUBSIDIOS_EXPLORACA...\n",
       "8  manualFeat     22  EBITDA, EBIT, Total_Assets, Total_Liabilities,..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_features_list = pd.read_csv(path_save + \"table_features_experience_oficial.csv\", encoding=\"latin-1\")\n",
    "display(df_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_features_list.loc[df_features_list['Experience'] == \"manualFeat\", [\"Columns\"]].values.tolist()[0][0].split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat5 = df_features_list.loc[df_features_list['Experience'] == \"feat5\", [\"Columns\"]].values.tolist()[0][0].split(\",\")\n",
    "feat5 = [s.strip() for s in feat5]\n",
    "feat7 = df_features_list.loc[df_features_list['Experience'] == \"feat7\", [\"Columns\"]].values.tolist()[0][0].split(\",\")\n",
    "feat7 = [s.strip() for s in feat7]\n",
    "manualFeat = df_features_list.loc[df_features_list['Experience'] == \"manualFeat\", [\"Columns\"]].values.tolist()[0][0].split(\",\")\n",
    "manualFeat = [s.strip() for s in manualFeat]\n",
    "feat5_new = feat5 + manualFeat\n",
    "feat7_new = feat7 + manualFeat\n",
    "feat5_new = list(set(feat5))\n",
    "feat7_new = list(set(feat7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GASTOS_DEPRECIACAO_AMORTIZA',\n",
       " 'Incentivo/Tx_Limite',\n",
       " 'Operating cash flow current liabilities',\n",
       " 'Dadosprojecto/N_Meses',\n",
       " 'SUBSIDIOS_EXPLORACAO',\n",
       " 'ATIVO_COR_ESTADO_OUT_ENTES_PUB',\n",
       " 'PASSIVO_COR_OUT_CONTAS_A_PAGAR',\n",
       " 'GP_REMUN_ORGAOS_SOCIAIS',\n",
       " 'IAE_VAR_INVENT_PROD',\n",
       " 'ATIVO_COR_DIFERIMENTOS',\n",
       " 'Resumo/Cae',\n",
       " 'IAE_VENDAS_MERCADORIAS',\n",
       " '2_IMG_COM_VENDAS',\n",
       " 'total debt / total assets',\n",
       " 'PASSIVO_NC_FINANCIAMENTOS_OBTD',\n",
       " 'ATIVO_NCOR_INV_FINANC_PQ_ENTID',\n",
       " 'Resumo/Nute_Norte',\n",
       " '3_IMG_EC_COMPRAS',\n",
       " 'Growth_Rate_Net_Sales_T3',\n",
       " 'NIF_Prom_anon',\n",
       " 'GP_SEG_ACID_TRAB_DOEN_PROF',\n",
       " 'IAE_AFT_QUANT_ESCR_LIQ_FIN',\n",
       " 'earnings before tax and interest / total asset',\n",
       " 'ATIVO_NCOR_PART_FINAN_EQV_PAT',\n",
       " 'CP_OUTRAS_VARIACAOES_CAP_PRO',\n",
       " 'Resumo/Investimento',\n",
       " 'IAE_AFT_TOTAL_AQUIS_EDIF',\n",
       " 'CP_RESERVAS_LEGAIS',\n",
       " 'Growth_Rate_Net_Sales_T2',\n",
       " '1_IMG_INT_FORN_SEREXTERN',\n",
       " 'PASSIVO_COR_ESTADO_OUT_ENT_PUB',\n",
       " 'IAE_PREST_SERV',\n",
       " 'IMPOSTO_RENDIMENTO_PERIODO',\n",
       " 'ATIVO_COR_ACCIONISTAS_SOCIOS',\n",
       " 'Inventory_Turnover',\n",
       " 'Total_Assets',\n",
       " 'ATIVO_COR_OUTRA_CONT_A_RECEBER',\n",
       " 'Gross income divided by sales',\n",
       " 'PASSIVO_COR_FORNCEDORES',\n",
       " 'Resumo/Distrito',\n",
       " 'ATIVO_COR_INVENTARIOS',\n",
       " 'RES_ANTES_DEPRECIACAO_GASTOS',\n",
       " 'CP_E_PASSIVO_TOTAL',\n",
       " '2_PESSOAL_NHT_PSE_MULHERES',\n",
       " 'total_assets_to_total_liabilities',\n",
       " 'PASSIVO_COR_OUTROS_PAS_CORRENTES',\n",
       " 'IAE_CMVMC_MERCADORIAS',\n",
       " 'IAE_COMPRAS',\n",
       " 'Resumo/Elegivel',\n",
       " '3_IMG_EC_REND_SUPLEM']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Txtfinanc/Fonte',\n",
       " 'Promotor/Nat_Jur',\n",
       " '3_IMG_EC_PREST_SERV',\n",
       " 'GASTOS_DEPRECIACAO_AMORTIZA',\n",
       " 'RES_ANTES_DEPRECIACAO_GASTOS',\n",
       " 'ATIVO_NCOR_PART_FINAN_EQV_PAT',\n",
       " 'Growth_Rate_Net_Sales_T3',\n",
       " 'ATIVO_NCOR_FIXOS_TANGIVEIS',\n",
       " 'ATIVO_NCOR_INV_FINANC_PQ_ENTID',\n",
       " 'Resumo/Lst_Po',\n",
       " '1_IMG_INT_AQUIS_ACT_INTANG',\n",
       " 'PROVISOES',\n",
       " 'CP_AJUST_EM_ACT_FINANCEIROS',\n",
       " 'PASSIVO_NC_FINANCIAMENTOS_OBTD',\n",
       " 'ATIVO_COR_INVENTARIOS',\n",
       " 'ATIVO_COR_ACCIONISTAS_SOCIOS',\n",
       " '3_IMG_EC_AQUIS_ACT_FIX_TANG',\n",
       " '2_N_PESSOAL_NHT_PSETP_REMUNERADAS',\n",
       " 'Resumo/Nute_Norte',\n",
       " '2_IMG_COM_AQUIS_ACT_FIX_TANG',\n",
       " '2_PESSOAL_NHT_PSE_TEMPO_PARCIAL',\n",
       " 'Critselb1/N_Mercados',\n",
       " 'Growth_Rate_Total_Assets_T3',\n",
       " 'CP_TOTAL',\n",
       " 'GP_REMUN_ORGAOS_SOCIAIS',\n",
       " '3_IMG_EC_COMPRAS',\n",
       " 'Growth_Rate_Net_Sales_T2',\n",
       " 'Growth_Rate_Net_Sales_T1',\n",
       " 'Operating cash flow current liabilities',\n",
       " 'IAE_CMVMC_MATER_PRIMAS',\n",
       " 'Resumo/Investimento',\n",
       " '1_PESSOAL_NMP_PSE_MULHERES',\n",
       " 'ATIVO_NCOR_PROPRI_INVESTIMENTO',\n",
       " 'ATIVO_COR_CLIENTES',\n",
       " 'Analisemercados/Direcao',\n",
       " '2_IMG_COM_FORN_SEREXTERN',\n",
       " 'Growth_Rate_Total_Assets_T2',\n",
       " 'ATIVO_COR_ADIANTAMENTOS_FORNEC',\n",
       " 'PASSIVO_COR_ADIANTA_DE_CLIENTES',\n",
       " 'IAE_AFT_TOTAL_AQUIS_EDIF',\n",
       " 'total_assets_to_total_liabilities',\n",
       " 'ATIVO_COR_ESTADO_OUT_ENTES_PUB',\n",
       " 'CMVMC',\n",
       " '1_IMG_INT_RS_OUTROS',\n",
       " 'CP_OUTRAS_RESERVAS',\n",
       " '1_PESSOAL_NMP_PSE_HOMENS',\n",
       " 'EBIT',\n",
       " 'IAE_AFT_TOTAL_AQUIS',\n",
       " 'Promotor/Concelho',\n",
       " 'CP_OUTRAS_VARIACAOES_CAP_PRO']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EBITDA',\n",
       " 'EBIT',\n",
       " 'Total_Assets',\n",
       " 'Total_Liabilities',\n",
       " 'total_assets_to_total_liabilities',\n",
       " 'Working capital divided by total assets',\n",
       " 'Gross income divided by sales',\n",
       " 'total debt / total assets',\n",
       " 'earnings before tax and interest / total asset',\n",
       " 'Operating cash flow current liabilities',\n",
       " 'Accounts_Receivables_Turnover',\n",
       " 'Creditors_Turnover',\n",
       " 'Inventory_Turnover',\n",
       " 'Average_Collection_Period_For_Receivables',\n",
       " 'Average_Payment_Period_To_Creditors',\n",
       " 'Average_Turnover_Period_For_Inventories',\n",
       " 'Growth_Rate_Net_Sales_T1',\n",
       " 'Growth_Rate_Net_Sales_T2',\n",
       " 'Growth_Rate_Net_Sales_T3',\n",
       " 'Growth_Rate_Total_Assets_T1',\n",
       " 'Growth_Rate_Total_Assets_T2',\n",
       " 'Growth_Rate_Total_Assets_T3']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manualFeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cenario 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TRAIN ####\n",
      "Accuracy: 0.79\n",
      "F1: 0.79\n",
      "Precision: 0.77\n",
      "Recall: 0.82\n",
      "ROC_AUC: 0.79\n",
      "#### TEST ####\n",
      "Accuracy: 0.72\n",
      "F1: 0.66\n",
      "Precision: 0.63\n",
      "Recall: 0.70\n",
      "ROC_AUC: 0.72\n"
     ]
    }
   ],
   "source": [
    "pipe = imblearnPipeline([('StandardScaler', StandardScaler()), ('over', SMOTE(random_state=21)), (\"SupportVectorClassification\", SVC(random_state=21))])\n",
    "X_train_balanced, y_train_balanced = pipe['over'].fit_resample(X_train[feat5_new], y_train)\n",
    "pipe.fit(X_train_balanced, y_train_balanced)\n",
    "# Predict train dataset\n",
    "print(\"#### TRAIN ####\")\n",
    "y_pred = pipe.predict(X_train_balanced)\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_train_balanced, y_pred)))\n",
    "print(\"F1: %.2f\" %(f1_score(y_train_balanced, y_pred)))\n",
    "print(\"Precision: %.2f\" %(precision_score(y_train_balanced, y_pred)))\n",
    "print(\"Recall: %.2f\" %(recall_score(y_train_balanced, y_pred)))\n",
    "print(\"ROC_AUC: %.2f\" %(roc_auc_score(y_train_balanced, y_pred)))\n",
    "\n",
    "# Predict test dataset\n",
    "print(\"#### TEST ####\")\n",
    "y_pred = pipe.predict(X_test[feat5_new])\n",
    "print(\"Accuracy: %.2f\" %(accuracy_score(y_test, y_pred)))\n",
    "print(\"F1: %.2f\" %(f1_score(y_test, y_pred)))\n",
    "print(\"Precision: %.2f\" %(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: %.2f\" %(recall_score(y_test, y_pred)))\n",
    "print(\"ROC_AUC: %.2f\" %(roc_auc_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TRAIN ####\n",
      "Accuracy: 0.79\n",
      "F1: 0.79\n",
      "Precision: 0.77\n",
      "Recall: 0.82\n",
      "ROC_AUC: 0.79\n",
      "#### TEST ####\n",
      "Accuracy: 0.72\n",
      "F1: 0.66\n",
      "Precision: 0.63\n",
      "Recall: 0.70\n",
      "ROC_AUC: 0.72\n"
     ]
    }
   ],
   "source": [
    "pipe = imblearnPipeline([('StandardScaler', StandardScaler()), ('under', RandomUnderSampler(random_state=21)), ('over', SMOTE(random_state=21)), (\"SupportVectorClassification\", SVC(random_state=21))])\n",
    "X_train_balanced, y_train_balanced = pipe['over'].fit_resample(X_train[feat5_new], y_train)\n",
    "pipe.fit(X_train_balanced, y_train_balanced)\n",
    "# Predict train dataset\n",
    "print(\"#### TRAIN ####\")\n",
    "y_pred = pipe.predict(X_train_balanced)\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_train_balanced, y_pred)))\n",
    "print(\"F1: %.2f\" %(f1_score(y_train_balanced, y_pred)))\n",
    "print(\"Precision: %.2f\" %(precision_score(y_train_balanced, y_pred)))\n",
    "print(\"Recall: %.2f\" %(recall_score(y_train_balanced, y_pred)))\n",
    "print(\"ROC_AUC: %.2f\" %(roc_auc_score(y_train_balanced, y_pred)))\n",
    "\n",
    "# Predict test dataset\n",
    "print(\"#### TEST ####\")\n",
    "y_pred = pipe.predict(X_test[feat5_new])\n",
    "print(\"Accuracy: %.2f\" %(accuracy_score(y_test, y_pred)))\n",
    "print(\"F1: %.2f\" %(f1_score(y_test, y_pred)))\n",
    "print(\"Precision: %.2f\" %(precision_score(y_test, y_pred)))\n",
    "print(\"Recall: %.2f\" %(recall_score(y_test, y_pred)))\n",
    "print(\"ROC_AUC: %.2f\" %(roc_auc_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py\", line 108, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py\", line 550, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py\", line 389, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.64880952        nan 0.68221414 0.63316938        nan 0.68217137\n",
      " 0.65595951        nan 0.68218563 0.66907613        nan 0.70729256\n",
      " 0.65358569        nan 0.67979755 0.65594525        nan 0.67388081]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.57536011        nan 0.50438084 0.53479022        nan 0.18178093\n",
      " 0.58153813        nan 0.53201058 0.54830471        nan 0.51638535\n",
      " 0.58060295        nan 0.5277638  0.53052395        nan 0.52104658]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.50394078        nan 0.5734184  0.48610622        nan 1.\n",
      " 0.50999399        nan 0.5570358  0.52841439        nan 0.61944167\n",
      " 0.50706367        nan 0.55417665 0.51198706        nan 0.54340518]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.67576271        nan 0.46265537 0.59819209        nan 0.10124294\n",
      " 0.67926554        nan 0.51677966 0.57468927        nan 0.4459887\n",
      " 0.68265537        nan 0.5099435  0.55084746        nan 0.50338983]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.65497276        nan 0.63249996 0.62536176        nan 0.55062147\n",
      " 0.66131133        nan 0.64473879 0.64784412        nan 0.64815575\n",
      " 0.66023696        nan 0.64131222 0.63216855        nan 0.63525761]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__C': 1, 'classifier__kernel': 'linear', 'resampler__sampling_strategy': 'auto'}\n",
      "Mean Accuracy: 0.6687\n",
      "Mean F1_score: 0.5112\n",
      "Mean Precision: 0.5746\n",
      "Mean Recall: 0.5251\n",
      "Mean Roc_auc: 0.6362\n",
      "Best estimator metrics\n",
      "Accuracy: 0.6416666666666667\n",
      "F1 Score: 0.6458377425044091\n",
      "Precision: 0.6606831664812756\n",
      "Recall: 0.6416666666666667\n",
      "ROC AUC: 0.6448557271932381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "pipeline = imblearnPipeline([('StandardScaler', StandardScaler()), ('resampler', SMOTE(random_state=21)), (\"classifier\", SVC(random_state=21))])\n",
    "\n",
    "# Define hyperparameters for resampler and classifier\n",
    "param_grid = {\n",
    "    'resampler__sampling_strategy': ['auto', 0.5, 0.75],\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Create custom scorers for F1 score and accuracy\n",
    "#f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "#accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Grid Search with multiple scoring metrics\n",
    "#scoring = {'F1': f1_scorer, 'Accuracy': accuracy_scorer}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scoring, refit='f1_score')\n",
    "grid_search.fit(X_train[feat5], y_train)\n",
    "\n",
    "# Get the best estimator and best hyperparameters\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Access the results including all metrics\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Print the metrics for each combination of hyperparameters\n",
    "for metric in ['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']:\n",
    "    mean_metric_values = np.nanmean(results[f'mean_test_{metric}']) #results[f'mean_test_{metric}']\n",
    "    print(f\"Mean {metric.capitalize()}: {mean_metric_values.mean():.4f}\")\n",
    "\n",
    "y_pred = best_estimator.predict(X_test[feat5])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  # ROC AUC is for binary classification\n",
    "print(\"Best estimator metrics\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__C': 10, 'classifier__kernel': 'rbf', 'resampler__sampling_strategy': 'auto', 'undersampler__sampling_strategy': 'auto'}\n",
      "Mean Accuracy: 0.6414\n",
      "Mean F1_score: 0.5542\n",
      "Mean Precision: 0.4964\n",
      "Mean Recall: 0.6356\n",
      "Mean Roc_auc: 0.6402\n",
      "Best estimator metrics\n",
      "Accuracy: 0.6722222222222223\n",
      "F1 Score: 0.6760398824909428\n",
      "Precision: 0.6998944658944659\n",
      "Recall: 0.6722222222222223\n",
      "ROC AUC: 0.6838628193918197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "210 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py\", line 108, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py\", line 550, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py\", line 409, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to generate new sample in the majority class while trying to remove samples. Please increase the ratio.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "120 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py\", line 208, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\base.py\", line 108, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py\", line 550, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\utils\\_validation.py\", line 389, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.62729541        nan 0.6213359         nan        nan        nan\n",
      "        nan        nan        nan 0.66072141        nan 0.6296122\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.63803821        nan 0.63685486        nan        nan        nan\n",
      "        nan        nan        nan 0.65479042        nan 0.66075706\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.62727402        nan 0.6332763         nan        nan        nan\n",
      "        nan        nan        nan 0.65352866        nan 0.65355004\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.55335144        nan 0.55521165        nan        nan        nan\n",
      "        nan        nan        nan 0.51554152        nan 0.53301622\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.56363184        nan 0.56767607        nan        nan        nan\n",
      "        nan        nan        nan 0.56706379        nan 0.55297873\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.54894847        nan 0.56265478        nan        nan        nan\n",
      "        nan        nan        nan 0.5809281         nan 0.54955924\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.48042366        nan 0.47699458        nan        nan        nan\n",
      "        nan        nan        nan 0.52680979        nan 0.48020458\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.49196154        nan 0.4919798         nan        nan        nan\n",
      "        nan        nan        nan 0.51106631        nan 0.51611436\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.47948254        nan 0.48800477        nan        nan        nan\n",
      "        nan        nan        nan 0.50690163        nan 0.50732152\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.65548023        nan 0.67248588        nan        nan        nan\n",
      "        nan        nan        nan 0.51694915        nan 0.60152542\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.66231638        nan 0.67581921        nan        nan        nan\n",
      "        nan        nan        nan 0.6420339         nan 0.60169492\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.64536723        nan 0.66903955        nan        nan        nan\n",
      "        nan        nan        nan 0.68248588        nan 0.60163842\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "c:\\Users\\afons\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.63373739        nan 0.63304892        nan        nan        nan\n",
      "        nan        nan        nan 0.62820784        nan 0.62333322\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.64359448        nan 0.64578422        nan        nan        nan\n",
      "        nan        nan        nan 0.65195477        nan 0.64749204\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.63143319        nan 0.64145997        nan        nan        nan\n",
      "        nan        nan        nan 0.66011824        nan 0.64189124\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "pipeline = imblearnPipeline([('StandardScaler', StandardScaler()), ('undersampler', RandomUnderSampler(random_state=21)), ('resampler', SMOTE(random_state=21)), (\"classifier\", SVC(random_state=21))])\n",
    "\n",
    "# Define hyperparameters for resampler and classifier\n",
    "param_grid = {\n",
    "    'resampler__sampling_strategy': ['auto', 0.5, 0.75],\n",
    "    'undersampler__sampling_strategy': ['auto', 0.5, 0.75],\n",
    "    'classifier__C': [0.1, 1, 10],\n",
    "    'classifier__kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "# Create custom scorers for F1 score and accuracy\n",
    "#f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "#accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Grid Search with multiple scoring metrics\n",
    "#scoring = {'F1': f1_scorer, 'Accuracy': accuracy_scorer}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scoring, refit='f1_score')\n",
    "grid_search.fit(X_train[feat5], y_train)\n",
    "\n",
    "# Get the best estimator and best hyperparameters\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Access the results including all metrics\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Print the metrics for each combination of hyperparameters\n",
    "for metric in ['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']:\n",
    "    mean_metric_values = np.nanmean(results[f'mean_test_{metric}']) #results[f'mean_test_{metric}']\n",
    "    print(f\"Mean {metric.capitalize()}: {mean_metric_values.mean():.4f}\")\n",
    "\n",
    "y_pred = best_estimator.predict(X_test[feat5])\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "roc_auc = roc_auc_score(y_test, y_pred)  # ROC AUC is for binary classification\n",
    "print(\"Best estimator metrics\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### TRAIN ####\n",
      "Accuracy: 0.98\n",
      "F1: 0.98\n",
      "Precision: 0.96\n",
      "Recall: 1.00\n",
      "ROC_AUC: 0.98\n",
      "#### TEST ####\n",
      "Accuracy: 0.72\n",
      "F1: 0.64\n",
      "Precision: 0.73\n",
      "Recall: 0.58\n",
      "ROC_AUC: 0.70\n"
     ]
    }
   ],
   "source": [
    "pipe = imblearnPipeline([('StandardScaler', StandardScaler()), ('under', RandomUnderSampler(random_state=21)), ('over', SMOTE(random_state=21)), (\"RandomForest\", RandomForestClassifier(random_state=21))])\n",
    "X_train_balanced, y_train_balanced = pipe['over'].fit_resample(X_train3[feat7], y_train3)\n",
    "pipe.fit(X_train_balanced, y_train_balanced)\n",
    "# Predict train dataset\n",
    "print(\"#### TRAIN ####\")\n",
    "y_pred = pipe.predict(X_train_balanced)\n",
    "print(\"Accuracy: %.2f\" % (accuracy_score(y_train_balanced, y_pred)))\n",
    "print(\"F1: %.2f\" %(f1_score(y_train_balanced, y_pred)))\n",
    "print(\"Precision: %.2f\" %(precision_score(y_train_balanced, y_pred)))\n",
    "print(\"Recall: %.2f\" %(recall_score(y_train_balanced, y_pred)))\n",
    "print(\"ROC_AUC: %.2f\" %(roc_auc_score(y_train_balanced, y_pred)))\n",
    "\n",
    "# Predict test dataset\n",
    "print(\"#### TEST ####\")\n",
    "y_pred = pipe.predict(X_test3[feat7])\n",
    "print(\"Accuracy: %.2f\" %(accuracy_score(y_test3, y_pred)))\n",
    "print(\"F1: %.2f\" %(f1_score(y_test3, y_pred)))\n",
    "print(\"Precision: %.2f\" %(precision_score(y_test3, y_pred)))\n",
    "print(\"Recall: %.2f\" %(recall_score(y_test3, y_pred)))\n",
    "print(\"ROC_AUC: %.2f\" %(roc_auc_score(y_test3, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "\n",
    "pipeline = imblearnPipeline([('StandardScaler', StandardScaler()), ('undersampler', RandomUnderSampler(random_state=21)), ('resampler', SMOTE(random_state=21)), (\"classifier\", RandomForestClassifier(random_state=21))])\n",
    "\n",
    "# Define hyperparameters for resampler and classifier\n",
    "param_grid = {\n",
    "    'resampler__sampling_strategy': ['auto', 0.5, 0.75],\n",
    "    'undersampler__sampling_strategy': ['auto', 0.5, 0.75],\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create custom scorers for F1 score and accuracy\n",
    "#f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "#accuracy_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Grid Search with multiple scoring metrics\n",
    "#scoring = {'F1': f1_scorer, 'Accuracy': accuracy_scorer}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=scoring, refit='f1_score')\n",
    "grid_search.fit(X_train3[feat7], y_train3)\n",
    "\n",
    "# Get the best estimator and best hyperparameters\n",
    "best_estimator = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Access the results including all metrics\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Print the metrics for each combination of hyperparameters\n",
    "for metric in ['accuracy', 'f1_score', 'precision', 'recall', 'roc_auc']:\n",
    "    mean_metric_values = np.nanmean(results[f'mean_test_{metric}']) #results[f'mean_test_{metric}']\n",
    "    print(f\"Mean {metric.capitalize()}: {mean_metric_values.mean():.4f}\")\n",
    "\n",
    "y_pred = best_estimator.predict(X_test3[feat7])\n",
    "accuracy = accuracy_score(y_test3, y_pred)\n",
    "f1 = f1_score(y_test3, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "precision = precision_score(y_test3, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "recall = recall_score(y_test3, y_pred, average='weighted')  # Adjust 'average' as needed\n",
    "roc_auc = roc_auc_score(y_test3, y_pred)  # ROC AUC is for binary classification\n",
    "print(\"Best estimator metrics\")\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"ROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
